{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CO2 Emissions Data - Basic EDA\n",
    "\n",
    "## Operations Covered:\n",
    "1. Data Loading\n",
    "2. Shape, Info, Dtypes\n",
    "3. Head & Tail\n",
    "4. Describe (Statistics)\n",
    "5. Null Values Analysis\n",
    "6. Duplicate Detection\n",
    "7. Value Counts\n",
    "8. Column Names Cleaning\n",
    "9. Data Cleaning\n",
    "10. Export Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('2006.csv')\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataframe\n",
    "print(\"Shape of the dataset:\")\n",
    "print(f\"Rows: {df.shape[0]}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types of all columns\n",
    "print(\"Data Types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All column names\n",
    "print(\"Column Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Head (First 5 Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tail (Last 5 Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Describe (Statistical Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for categorical columns\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Null Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values count per column\n",
    "print(\"Null Values Count:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values percentage per column\n",
    "print(\"Null Values Percentage:\")\n",
    "null_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "null_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total null values in dataset\n",
    "total_nulls = df.isnull().sum().sum()\n",
    "total_cells = df.shape[0] * df.shape[1]\n",
    "print(f\"Total Null Values: {total_nulls}\")\n",
    "print(f\"Total Cells: {total_cells}\")\n",
    "print(f\"Null Percentage: {(total_nulls/total_cells*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with null values\n",
    "print(\"Columns with Null Values:\")\n",
    "null_columns = df.columns[df.isnull().any()].tolist()\n",
    "print(null_columns)\n",
    "print(f\"\\nTotal columns with nulls: {len(null_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Duplicate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Total Duplicate Rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show duplicate rows (if any)\n",
    "if duplicate_count > 0:\n",
    "    print(\"Duplicate Rows:\")\n",
    "    df[df.duplicated()]\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Value Counts (Categorical Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical Columns: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for IPCC_annex\n",
    "print(\"Value Counts - IPCC_annex:\")\n",
    "df['IPCC_annex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for Substance\n",
    "print(\"Value Counts - Substance:\")\n",
    "df['Substance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for fossil_bio\n",
    "print(\"Value Counts - fossil_bio:\")\n",
    "df['fossil_bio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for IPCC emission categories\n",
    "print(\"Value Counts - ipcc_code_2006_for_standard_report_name:\")\n",
    "df['ipcc_code_2006_for_standard_report_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique countries\n",
    "print(f\"Unique Countries: {df['Name'].nunique()}\")\n",
    "print(f\"Unique Country Codes: {df['Country_code_A3'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Column Names Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current column names\n",
    "print(\"Current Column Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names - strip whitespace and convert to lowercase (optional)\n",
    "# Keeping original names as they are already clean\n",
    "\n",
    "# Check if column names have any issues\n",
    "print(\"Column Names Analysis:\")\n",
    "print(f\"- Columns with leading/trailing spaces: {sum(df.columns != df.columns.str.strip())}\")\n",
    "print(f\"- Columns with special characters: {sum(df.columns.str.contains(r'[^a-zA-Z0-9_]'))}\")\n",
    "print(f\"- Columns starting with number: {sum(df.columns.str.match(r'^\\d'))}\")\n",
    "\n",
    "print(\"\\nColumn names are already clean!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_cleaned = df.copy()\n",
    "print(f\"Original shape: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove duplicate rows\n",
    "initial_rows = len(df_cleaned)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "removed_duplicates = initial_rows - len(df_cleaned)\n",
    "print(f\"Removed {removed_duplicates} duplicate rows\")\n",
    "print(f\"Shape after removing duplicates: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check for negative values in year columns\n",
    "year_cols = [col for col in df_cleaned.columns if col.startswith('Y_')]\n",
    "print(f\"Year columns found: {len(year_cols)}\")\n",
    "\n",
    "negative_count = 0\n",
    "for col in year_cols:\n",
    "    neg_count = (df_cleaned[col] < 0).sum()\n",
    "    if neg_count > 0:\n",
    "        print(f\"{col}: {neg_count} negative values\")\n",
    "        negative_count += neg_count\n",
    "\n",
    "print(f\"\\nTotal negative values found: {negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Replace negative values with NaN (emissions should not be negative)\n",
    "for col in year_cols:\n",
    "    df_cleaned.loc[df_cleaned[col] < 0, col] = np.nan\n",
    "\n",
    "print(f\"Replaced {negative_count} negative values with NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Final shape after cleaning\n",
    "print(\"=\"*50)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df_cleaned.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_cleaned)}\")\n",
    "print(f\"Negative values replaced with NaN: {negative_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Cleaned Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data info\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data head\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data describe\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Export Cleaned Data to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data to Excel\n",
    "output_file = 'CO2_Emissions_Cleaned_Data.xlsx'\n",
    "df_cleaned.to_excel(output_file, index=False)\n",
    "print(f\"Cleaned data exported to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
