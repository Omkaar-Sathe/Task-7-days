{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA - CO2 Emissions Dataset (1996)\n",
    "\n",
    "This notebook covers basic data exploration and cleaning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/z/my-project/upload/1996.csv', low_memory=False)\n",
    "\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic DataFrame Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "print(\"Shape of DataFrame:\")\n",
    "print(f\"Rows: {df.shape[0]}\")\n",
    "print(f\"Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame info\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "print(\"Column Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows\n",
    "print(\"First 5 Rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 rows\n",
    "print(\"Last 5 Rows:\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "print(\"Descriptive Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for all columns (including categorical)\n",
    "print(\"Descriptive Statistics (All Columns):\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Null Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total null values in dataset\n",
    "total_nulls = df.isnull().sum().sum()\n",
    "print(f\"Total Null Values: {total_nulls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values by column\n",
    "print(\"Null Values by Column:\")\n",
    "null_counts = df.isnull().sum()\n",
    "null_pct = (df.isnull().sum() / len(df)) * 100\n",
    "null_df = pd.DataFrame({\n",
    "    'Null Count': null_counts,\n",
    "    'Null Percentage': null_pct.round(2)\n",
    "})\n",
    "null_df = null_df[null_df['Null Count'] > 0].sort_values('Null Count', ascending=False)\n",
    "print(null_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values by row\n",
    "print(\"Null Values by Row (Top 10 rows with most nulls):\")\n",
    "null_by_row = df.isnull().sum(axis=1)\n",
    "print(null_by_row.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows with all null values\n",
    "all_null_rows = df.isnull().all(axis=1).sum()\n",
    "print(f\"Rows with all null values: {all_null_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Duplicate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(f\"Total Duplicate Rows: {duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates based on key columns\n",
    "key_columns = ['Country_code_A3', 'ipcc_code_1996_for_standard_report', 'Substance']\n",
    "key_cols_exist = [col for col in key_columns if col in df.columns]\n",
    "\n",
    "if key_cols_exist:\n",
    "    duplicates_on_keys = df.duplicated(subset=key_cols_exist, keep=False).sum()\n",
    "    print(f\"Duplicate rows based on {key_cols_exist}: {duplicates_on_keys}\")\n",
    "else:\n",
    "    print(\"Key columns not found in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show duplicate rows (if any)\n",
    "if duplicate_rows > 0:\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(df[df.duplicated(keep=False)])\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Column Name Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with unnamed or problematic names\n",
    "print(\"Columns with 'Unnamed' in name:\")\n",
    "unnamed_cols = [col for col in df.columns if 'Unnamed' in str(col)]\n",
    "print(f\"Count: {len(unnamed_cols)}\")\n",
    "print(unnamed_cols[:10])  # Show first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify actual data columns vs empty columns\n",
    "print(\"\\nAnalyzing column content...\")\n",
    "\n",
    "# Check which columns have data\n",
    "non_null_counts = df.count()\n",
    "empty_cols = non_null_counts[non_null_counts == 0].index.tolist()\n",
    "data_cols = non_null_counts[non_null_counts > 0].index.tolist()\n",
    "\n",
    "print(f\"Empty columns (all null): {len(empty_cols)}\")\n",
    "print(f\"Columns with data: {len(data_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns with data\n",
    "print(\"Columns with data:\")\n",
    "print(data_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaned dataframe - remove empty columns\n",
    "df_cleaned = df[data_cols].copy()\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df_cleaned.shape}\")\n",
    "print(f\"Columns removed: {df.shape[1] - df_cleaned.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity (strip whitespace, lowercase)\n",
    "print(\"\\nCleaning column names...\")\n",
    "df_cleaned.columns = df_cleaned.columns.str.strip()\n",
    "print(\"Column names cleaned (whitespace stripped)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cleaned column names\n",
    "print(\"Cleaned DataFrame Columns:\")\n",
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Value Counts for Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for each categorical column\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Value Counts for: {col}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    unique_count = df_cleaned[col].nunique()\n",
    "    print(f\"Unique values: {unique_count}\")\n",
    "    \n",
    "    if unique_count <= 20:\n",
    "        print(df_cleaned[col].value_counts())\n",
    "    else:\n",
    "        print(f\"Top 15 values:\")\n",
    "        print(df_cleaned[col].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Value Counts for Key Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPCC Annex\n",
    "if 'IPCC_annex' in df_cleaned.columns:\n",
    "    print(\"IPCC Annex Distribution:\")\n",
    "    print(df_cleaned['IPCC_annex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country Groups\n",
    "if 'C_group_IM24_sh' in df_cleaned.columns:\n",
    "    print(\"\\nCountry Groups Distribution:\")\n",
    "    print(df_cleaned['C_group_IM24_sh'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substance\n",
    "if 'Substance' in df_cleaned.columns:\n",
    "    print(\"\\nSubstance Distribution:\")\n",
    "    print(df_cleaned['Substance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fossil/Bio classification\n",
    "if 'fossil_bio' in df_cleaned.columns:\n",
    "    print(\"\\nFossil/Bio Classification:\")\n",
    "    print(df_cleaned['fossil_bio'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPCC Emission Categories\n",
    "if 'ipcc_code_1996_for_standard_report_name' in df_cleaned.columns:\n",
    "    print(\"\\nIPCC Emission Categories:\")\n",
    "    print(df_cleaned['ipcc_code_1996_for_standard_report_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries\n",
    "if 'Name' in df_cleaned.columns:\n",
    "    print(\"\\nCountries (Count of records per country - Top 20):\")\n",
    "    print(df_cleaned['Name'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics for Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns (year columns)\n",
    "year_cols = [col for col in df_cleaned.columns if col.startswith('Y_')]\n",
    "print(f\"Year columns found: {len(year_cols)}\")\n",
    "print(f\"Year range: {year_cols[0]} to {year_cols[-1] if year_cols else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year columns to numeric\n",
    "print(\"Converting year columns to numeric...\")\n",
    "for col in year_cols:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "\n",
    "print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for year columns\n",
    "if year_cols:\n",
    "    print(\"Descriptive Statistics for Year Columns:\")\n",
    "    print(df_cleaned[year_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values in year columns\n",
    "if year_cols:\n",
    "    print(\"Null Values in Year Columns:\")\n",
    "    year_nulls = df_cleaned[year_cols].isnull().sum()\n",
    "    print(year_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Cleaned DataFrame Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL CLEANED DATAFRAME SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nShape: {df_cleaned.shape}\")\n",
    "print(f\"Rows: {df_cleaned.shape[0]}\")\n",
    "print(f\"Columns: {df_cleaned.shape[1]}\")\n",
    "print(f\"\\nTotal Null Values: {df_cleaned.isnull().sum().sum()}\")\n",
    "print(f\"Total Duplicate Rows: {df_cleaned.duplicated().sum()}\")\n",
    "print(f\"\\nColumn Names:\")\n",
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DataFrame info\n",
    "print(\"Final DataFrame Info:\")\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview cleaned data\n",
    "print(\"Cleaned Data - First 5 Rows:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview cleaned data\n",
    "print(\"Cleaned Data - Last 5 Rows:\")\n",
    "df_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataframe\n",
    "df_cleaned.to_csv('/home/z/my-project/download/cleaned_1996_data.csv', index=False)\n",
    "print(\"Cleaned data saved to: /home/z/my-project/download/cleaned_1996_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Quick Reference Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dictionary\n",
    "summary = {\n",
    "    'Metric': [\n",
    "        'Original Rows',\n",
    "        'Original Columns',\n",
    "        'Cleaned Rows',\n",
    "        'Cleaned Columns',\n",
    "        'Empty Columns Removed',\n",
    "        'Total Null Values (Original)',\n",
    "        'Total Null Values (Cleaned)',\n",
    "        'Duplicate Rows',\n",
    "        'Categorical Columns',\n",
    "        'Numerical (Year) Columns',\n",
    "        'Year Range'\n",
    "    ],\n",
    "    'Value': [\n",
    "        df.shape[0],\n",
    "        df.shape[1],\n",
    "        df_cleaned.shape[0],\n",
    "        df_cleaned.shape[1],\n",
    "        df.shape[1] - df_cleaned.shape[1],\n",
    "        df.isnull().sum().sum(),\n",
    "        df_cleaned.isnull().sum().sum(),\n",
    "        df_cleaned.duplicated().sum(),\n",
    "        len(categorical_cols),\n",
    "        len(year_cols),\n",
    "        f\"{year_cols[0].replace('Y_', '')} - {year_cols[-1].replace('Y_', '')}\" if year_cols else 'N/A'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"=\"*60)\n",
    "print(\"EDA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
